{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    \"\"\"\n        Load the data:\n            - 14,034 images to train the network.\n            - 3,000 images to evaluate how accurately the network learned to classify images.\n    \"\"\"\n    \n    datasets = ['/kaggle/input/intel-image-classification/seg_train/seg_train', '/kaggle/input/intel-image-classification/seg_test/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output\n                \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images,train_labels=shuffle(train_images,train_labels,random_state=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images=train_images/255\ntest_images=test_images/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_,train_count=np.unique(train_labels,return_counts=True)\n_,test_count=np.unique(test_labels,return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({'train':train_count,'test':test_count},index=class_names).plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(train_count,labels=class_names,autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(test_count,labels=class_names,autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index=np.random.randint(train_images.shape[0])\nindex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_random_image(class_names,train_images,train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread('/kaggle/input/intel-image-classification/seg_test/seg_test/sea/21568.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \nimage=cv2.resize(image,IMAGE_SIZE)\nplt.imshow(image)\nplt.imshow(train_images[9959])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating a basic CNN model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n    tf.keras.layers.Dense(6,tf.nn.softmax)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(train_images,train_labels,batch_size=128,epochs=20,validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_images,test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels=[]\nfor i in range(len(predictions)):\n    pred=np.argmax(predictions[i])\n    pred_labels.append(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(test_labels,pred_labels)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_random_image(class_names, test_images, pred_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CM=confusion_matrix(test_labels,pred_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.heatmap(CM,annot=True,xticklabels=class_names,yticklabels=class_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Using Pretrained Model VGG Imagenet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG16(weights='imagenet',include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features=model.predict(train_images)\ntest_features=model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train,x,y,z=train_features.shape\nn_test, x,y,z=test_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x,y,z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2=tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x,y,z)),\n    tf.keras.layers.Dense(50,activation = tf.nn.relu),\n    tf.keras.layers.Dense(6,activation = tf.nn.softmax)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"History2=model2.fit(train_features,train_labels,batch_size=128,epochs=15,validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.evaluate(test_features,test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model2.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"pred_labels=[]\nfor i in range(len(predictions)):\n    pred=np.argmax(predictions[i])\n    pred_labels.append(pred)"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(test_labels,pred_labels)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_random_image(class_names,test_images,pred_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(test_labels,pred_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.heatmap(cm,annot=True,xticklabels=class_names,yticklabels=class_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ensemble Neural Network**"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(seed=1997)\nn_estimators=10\nmax_samples=0.8\nmax_samples*=n_train\nmax_samples=int(max_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=list()\nrandom=np.random.randint(50,100,size=n_estimators)\nfor i in range(n_estimators):\n    model=tf.keras.Sequential([\n        tf.keras.layers.Flatten(input_shape=(x,y,z)),\n        tf.keras.layers.Dense(random[i],activation=tf.nn.relu),\n        tf.keras.layers.Dense(6,activation=tf.nn.softmax)\n    ])\n    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n    models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Histories=[]\nfor i in range(n_estimators):\n    train_idx=np.random.choice(len(train_features),max_samples)\n    Histories.append(models[i].fit(train_features[train_idx],train_labels[train_idx],epochs=10,batch_size=128,validation_split=0.1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=[]\nfor i in range(n_estimators):\n    predictions.append(models[i].predict(test_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=np.array(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=predictions.sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels=predictions.argmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy=accuracy_score(test_labels,pred_labels)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fine Tuning VGG ImageNet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=VGG16(weights='imagenet',include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Model(model.inputs,model.layers[-5].output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features=model.predict(train_images)\ntest_features=model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input,Dense,Conv2D,Activation,MaxPooling2D,Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2=VGG16(weights='imagenet',include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.summary()","execution_count":100,"outputs":[{"output_type":"stream","text":"Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         (None, None, None, 3)     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape=model2.layers[-4].get_input_shape_at(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layer_input=Input(shape=(9,9,512))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=layer_input","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model2.layers[-4::1]:\n    x=layer(x)\nx=Conv2D(64,(3,3),activation='relu')(x)\nx=MaxPooling2D(pool_size=(2,2))(x)\nx=Flatten()(x)\nx=Dense(100,activation='relu')(x)\nx=Dense(6,activation='softmax')(x)\nnew_model=Model(layer_input,x)","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_model.summary()","execution_count":103,"outputs":[{"output_type":"stream","text":"Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         (None, 9, 9, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        multiple                  2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        multiple                  2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        multiple                  2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   multiple                  0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 2, 2, 64)          294976    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 100)               6500      \n_________________________________________________________________\ndense_2 (Dense)              (None, 6)                 606       \n=================================================================\nTotal params: 7,381,506\nTrainable params: 7,381,506\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":104,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"History3=new_model.fit(train_features,train_labels,epochs=15,validation_split=0.2,batch_size=128)","execution_count":106,"outputs":[{"output_type":"stream","text":"Train on 11227 samples, validate on 2807 samples\nEpoch 1/15\n11227/11227 [==============================] - 5s 458us/step - loss: 0.2564 - accuracy: 0.9135 - val_loss: 0.2372 - val_accuracy: 0.9191\nEpoch 2/15\n11227/11227 [==============================] - 5s 418us/step - loss: 0.2083 - accuracy: 0.9281 - val_loss: 0.2629 - val_accuracy: 0.9116\nEpoch 3/15\n11227/11227 [==============================] - 5s 417us/step - loss: 0.1742 - accuracy: 0.9395 - val_loss: 0.2445 - val_accuracy: 0.9177\nEpoch 4/15\n11227/11227 [==============================] - 5s 418us/step - loss: 0.1505 - accuracy: 0.9461 - val_loss: 0.2479 - val_accuracy: 0.9152\nEpoch 5/15\n11227/11227 [==============================] - 5s 414us/step - loss: 0.1172 - accuracy: 0.9592 - val_loss: 0.2786 - val_accuracy: 0.9124\nEpoch 6/15\n11227/11227 [==============================] - 5s 413us/step - loss: 0.1076 - accuracy: 0.9621 - val_loss: 0.3375 - val_accuracy: 0.8978\nEpoch 7/15\n11227/11227 [==============================] - 5s 419us/step - loss: 0.0948 - accuracy: 0.9641 - val_loss: 0.3849 - val_accuracy: 0.9031\nEpoch 8/15\n11227/11227 [==============================] - 5s 431us/step - loss: 0.0627 - accuracy: 0.9790 - val_loss: 0.5491 - val_accuracy: 0.8817\nEpoch 9/15\n11227/11227 [==============================] - 5s 439us/step - loss: 0.0691 - accuracy: 0.9754 - val_loss: 0.3612 - val_accuracy: 0.9156\nEpoch 10/15\n11227/11227 [==============================] - 5s 425us/step - loss: 0.0468 - accuracy: 0.9828 - val_loss: 0.4333 - val_accuracy: 0.9095\nEpoch 11/15\n11227/11227 [==============================] - 5s 418us/step - loss: 0.0543 - accuracy: 0.9830 - val_loss: 0.5313 - val_accuracy: 0.8945\nEpoch 12/15\n11227/11227 [==============================] - 5s 414us/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 0.4635 - val_accuracy: 0.9092\nEpoch 13/15\n11227/11227 [==============================] - 5s 414us/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.5081 - val_accuracy: 0.9027\nEpoch 14/15\n11227/11227 [==============================] - 5s 421us/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 0.4656 - val_accuracy: 0.9070\nEpoch 15/15\n11227/11227 [==============================] - 5s 413us/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.4718 - val_accuracy: 0.9095\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=new_model.predict(test_features)","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels=[]\nfor i in range(0,len(predictions)):\n    pred_labels.append(np.argmax(predictions[i]))","execution_count":108,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(test_labels,pred_labels)","execution_count":109,"outputs":[{"output_type":"execute_result","execution_count":109,"data":{"text/plain":"0.8893333333333333"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}